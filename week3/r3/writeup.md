# Data 512 week 2 reading
Readings
- Wang, Tricia. Why Big Data Needs Thick Data. Ethnography Matters, 2016. https://medium.com/ethnography-matters/why-big-data-needs-thick-data-b4b3e75e3d7
- Kery, M. B., Radensky, M., Arya, M., John, B. E., & Myers, B. A. (2018). The Story in the Notebook: Exploratory Data Science using a Literate Programming Tool. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI’18, 1–11. https://doi.org/10.1145/3173574.3173748 https://marybethkery.com/projects/Verdant/Kery-The-Story-in-the-Notebook-Exploratory-Data-Science-using-a-Literate-Programming-Tool.pdf

Reflection:

Which Reading?: Ethnography Matters

How does this reading inform your understanding of human centered data science?
Tricia Wang makes a convincing argument that we cant focus too much on numbers. I think this has happened throughout history, where companies or individuals focus too much on something that is easily measured and they are convinced is invaluable in improving. For example, consider education, we place so much value on a student GPA, we sometimes do not consider the many other factors that make them unique and valuable individuals. Conseuqently, colleges across the country have to take balanced approached between the GPA and their personal statements and experiences.


One question that came to mind.
I suppose this isnt a matter of handling more qualitative data, where there are more string types in our data. Rather I think Tricia Wang is saying that we need this "thick" data to guide those who make decisions with quantitative data, so they know when they should or not respond to the metrics they have collected and if they hsould be measuring different signals instead. I suppose my question would be, is thick data meant to guide the quantitative measures of success? (ex, revenue, units sold, social media following ..), and/or is it meant to make sure we dont over or under-react to the quantitative signals we have?

Which Reading:
The Story in the Notebook: Exploratory Data Science using a Literate Programming Tool

How does this reading inform your understanding of human centered data science?
There is avid discussion of literate programming, and how various data scientists try to maintain the principles of reproducibility using jupyter notebooks. It was somehow encouraging to see that the issues I face using jupyter is shared amongst colleagues. I often find myself deleting cells that showed avenues that didnt have promising results. However, those same cells could still be useful later for bits of code or steps followed to get there. I think that some more tools or processes to help data scientists keep track of our organic discover process in code and notebooks can be extremely beneficial

One question that came to mind.
What could I be doing to help in this process. Is there something that I may be doing or colleagues may be doing that isnt necessarily well known amongst the data science community? There may be a lack of communication that could be stalling this process.
