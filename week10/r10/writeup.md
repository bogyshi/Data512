# Data 512 week 10 reading
Readings
- Read and reflect: Barocas, S., & Boyd, D. (2017). Engaging the ethics of data science in practice. Communications of the ACM, 60(11), 23â€“25. https://doi.org/10.1145/3144172 (PDF available on Canvas)
# Notes:

Such a critique is not new. In the
1990s, Science and Technology Studies
(STS) scholars challenged efforts by AI
researchers to replicate human behav-
iors and organizational functions in
software (for example, Collins 3 ). The
scholarship from the time was damn-
ing: expert systems routinely failed,
critical researchers argued, because
developers had impoverished under-
standings of the social worlds into
which they intended to introduce their
tools.

This reminds me of a point made by our former Statistical Learning professor, Zaid Harahouchi, that there was a time when AI and ML was super hot and wesome, but then it flopped and everyone lost trust in it. Until now. However, this might not be until much later.

When is the
ability to meaningfully interrogate a
model sufficiently important to justify
some cost in performance?

Looks like our GAM solves this problem!

debated the different qualities that an
intuitive sense of fairness might imply:
that a risk score is equally accurate in
predicting the likelihood of recidivism
for members of different racial groups;
that members of different groups have
the same chance of being wrongly pre-
dicted to recidivate; or that failure to
predict recidivism happens at the same
rate across groups.

A very good point

Many data scientists are also deeply
disturbed by those who are coming
into the field without rigorous train-
ing and those who are playing into the
hype by promising analyses that are
not technically or socially responsible

Couldnt agree more.


# Reflection

## How does this reading inform your understanding of human centered data science?

This article re-enforces and highlights some key thoughts I have had throughout my career as a data scientist so far. We need to have clear conversations of fairness when implementing new models (but how many times is it really applicable?) and really gauge the ability of our models to achieve certain results. I hope to gain a much deeper understanding of what models can realistically achieve in various business cases so I know when something is or is not being used properly.

On the note of critics, I havent dealt with them in any great capacity, but I can imagine that having twitter users or potentially people you even know personally attacking you for a model you may or may not have helped develop can be irritating. Who are they to know how complex it was to create and implement? Since everyone is a critic, and not everyone is a data scientist, I could imagine that sometimes it may be hard to find the critics who may actually be able to contribute to the discussion.

## One question that came to mind.

How can we find these critics that are willing and able to work with us to help solve shared challenges in a professional manner? I feel like this is a good idea, but hard to execute.
