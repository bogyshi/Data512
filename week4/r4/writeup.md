# Data 512 week 4 reading
Readings
- Barocas, Solan and Nissenbaum, Helen. Big Data's End Run around Anonymity and Consent. In Privacy, Big Data, and the Public Good. 2014.

# Notes:

'consider as a quick illustration
the rules limiting access to results of an HIV test. Generally, we might
consider embarrassment, job security, danger to sexual partners, autonomy,
various freedoms, and so on.'

Lots of fluff in this article, on page 7 and the authors havent gotten to their point of why privacy is so important to them

now we got it
'Privacy is important, in part, because it implicates these other
values. Second, doing so also allows us to better formulate interventions,
regulations, or remediation for the sake of these values.'

Basically, by protecting our privacy, or the disruption of information flow from what we expect, we can prevent that worst case bad stuff we talked about , like discriminating college admissions students because of socio economic class.

# Reflection:

Which Reading?:  Barocas, Solan and Nissenbaum, Helen. Big Data's End Run around Anonymity and Consent

## How does this reading inform your understanding of human centered data science?
This article presents a "big picture" for big data and its impacts on society. It doesn't scold the researchers who are working on algorithms that will ensure anonymity and privacy, but rather says we have another question to answer. What does anonymity and privacy protect us from? These pseudonyms that are tracked by various organizations can be combined by other coprorations of malicious users to determine true identities. Overall, it seems that large data promises to be just as invasive, even if we hide our names. I enjoyed reading this as it gives some perspective on the big picture and questions we need to ask as scientists on this data. We will likely be looking for exactly these unrecorded data via pattern recognition in the data we do have. Understanding what its being used for and why and why not the consumer might need to know is crucial if we dont want our worst dreams to become a reality.

## One question that came to mind.
Even if corporations that collect data were more encompassing in their informed consent policy, and told users in plain text that they would collect this data and then try to figure out their work routine and general patterns of life for example, would we care? Or would we only care if that ended up impacting our lives negatively?
