# Data 512 week 2 reading
Readings
-  Mixed Messages? The Limits of Automated Social Media Content Analysis, Duarte, N., Llanso, E., & Loup, A. (2018)
  https://cdt.org/files/2017/12/FAT-conference-draft-2018.pdf

Reflection:

How does this reading inform your understanding of human centered data science?

Duarte, Llanso, and Loup discuss the many limitations and concerns regarding the use of machine learning models and NLP on tasks ranging from hate speech, terrorist messages, and other unpleasent social media posting. In particular they addressed 5 limitations of NLP on social media platforms. This is by no means a subject that is not debated in a heated fashion. There have been TED talks on how google limits the first few links and recommendations we see when entering a query based on a personalized ML algorithm to the user. Similarly, the impacts of ML algorithms on the world at large must be considered. Even in the google search algorithm, how it chooses what we see versus what others see can make profound impacts on our worldview and personal opinions we develop. Similarly, having NLP decide what is considered safe or unsafe for massive consumption can be Similarly devestating. When we consider who these tools are for, its for social media platforms aiming to provide an enjoyable experience for as many users as possible, in hopes that they will stay on their platform (at least for most I would suppose). The impact on the customer is where most concern is placed in this article. Is there a bisa? The article sites languages, dialects, and slang that can be misinterpreted by an ML algorithm if you do not consider the context (ex imma, and fag in reference to a cigarette). These are benign examples, but we can imagine that by censoring users who mean no harm, we can both alienate particular demographics from the platform, as well as silence those who deserve the right to express opinion on politics, religion, and current events.

One question that came to mind.

There is clearly some cause for concern as various platforms and teams use out of the box or even bench work NLP models. The authors take great care to highlight what both researchers and policy makers should be wary of when utilizing these services along with recommendations of courses of action. They even espouse values of replicability, and open sourcing so that others can keep us honest. However, what shall we as the consumer of these services be wary of?What courses of action can we take? I understand we can opt out of some data collection services, and use services such as duck duck go, but in general, when faced with increasing use of NLP, what should we be wary of? I believe there can be some discussion on this point that I would find particularly informative,
